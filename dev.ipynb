{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import GPT\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "from utils import BatchLoader, estimate_loss, train_loop\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # number of independent sequences that'll be processed in parallel\n",
    "block_size = 128  # maximum context length for the preds\n",
    "max_iters = 1000\n",
    "eval_interval = 200\n",
    "learning_rate = 3e-4\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "eval_iters = 200\n",
    "n_embd = 256\n",
    "n_head = 4\n",
    "n_blocks = 4\n",
    "dropout = 0.2\n",
    "# --------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# data preparation\n",
    "text = open(\"dataset/tinyshakespeare.txt\", \"r\").read()\n",
    "# set up the vocabulary\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "tokenizer = Tokenizer(chars)\n",
    "\n",
    "data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
    "\n",
    "n = int(0.9 * len(data))  # first 90% will be the training set\n",
    "n1 = int(0.98 * len(data))  # 90-98% will be the validation set and the last 2% will be the calibration set for the paper\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:n1]\n",
    "calibrate_data = data[n1:]\n",
    "\n",
    "train_loader = BatchLoader(train_data, block_size, batch_size, device, name=\"train\")\n",
    "val_loader = BatchLoader(val_data, block_size, batch_size, device, name=\"val\")\n",
    "calibration_loader = BatchLoader(calibrate_data, block_size, batch_size, device, name=\"calibrate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIFORM BASELINE:  4.174387454986572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 800: train loss 2.0373, val loss 2.0801: 100%|██████████| 1000/1000 [03:49<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is done!\n",
      "\n",
      "\n",
      "Appy ecreace flesh, quince bouboal ford?\n",
      "Habr And sirear his spown Poghe so inge jit shay.\n",
      "\n",
      "ARENTEO:\n",
      "Thave in you ye shaven dou mesoel!\n",
      "Nothe briffor to I fulllf I theeipouldss;\n",
      "Wind swird fre piodly besewel've is lod;\n",
      "An ing, hiplow to wat Lrd mers, hand be not hensy?\n",
      "Whare to blikne, fore, ups me thons!\n",
      "Hing sistris have wencthisus,\n",
      "Ser son: the For 'tlevembabe;\n",
      "Tor ben alinss me cewids reme\n",
      "jr kenind mu; ast hip aght nor. hich nackis me, thay\n",
      "Phey Karrd sonfor kim pate ard.\n",
      "You moneto wour s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPT(vocab_size, block_size, n_embd, n_head, n_blocks, device, dropout)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "training_losses = train_loop(model, optimizer, vocab_size, train_loader, [train_loader, val_loader], max_iters, eval_interval, eval_iters)\n",
    "\n",
    "print(\"training is done!\")\n",
    "\n",
    "plt.title(\"training losses\")\n",
    "plt.plot(training_losses)\n",
    "plt.savefig(\"training_losses.png\")\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(tokenizer.decode(model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save\n",
    "\n",
    "model_params = {\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"block_size\": block_size,\n",
    "    \"n_embd\": n_embd,\n",
    "    \"n_head\": n_head,\n",
    "    \"n_blocks\": n_blocks,\n",
    "    \"dropout\": dropout,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "save(model, tokenizer, model_params, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alperiox/Desktop/coding/paper-implts/Compact_Language_Models_240714679/utils.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_dir / \"model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "loaded_model, tokenizer = load(GPT, \"model\")\n",
    "loaded_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_head_importance_hook(module, ins, outs) -> None: # TODO: does the importance calculation returns the correct values for each head? \n",
    "    \"\"\" calculates the multi-head-attention layer's importance per head \"\"\"\n",
    "\n",
    "    # outs.shape = (B, T, E) where B: batch_size, T: num tokens, E: embedding size\n",
    "    # the importance is calculated as summing the L2 norm of the attn outputs on B and T dimensions\n",
    "    outs_flat = outs.view(-1, outs.shape[-1]) # (b,t,e) -> (b*t, e)\n",
    "    importance = torch.linalg.vector_norm(outs_flat.detach().cpu(), ord=2, dim=-1).sum()\n",
    "\n",
    "    module.calculated_importance = importance\n",
    "    \n",
    "    # print(outs_flat.shape)\n",
    "    # print(\"module:\", module.__class__.__name__, end=\" \")\n",
    "    # print(\"importance:\", importance)\n",
    "    print(f\"{module.__class__.__name__} importance: {importance.shape}\")\n",
    "\n",
    "def neuron_importance_hook(module, ins, outs) -> None:\n",
    "    \"\"\" calculates the neuron importance for the given layer \"\"\" \n",
    "    \n",
    "    # for each neuron in the ffwd layer, we will simply sum up the output columns\n",
    "    # as they're the activations of individual neurons\n",
    "    # calculate the importances\n",
    "    # importance = outs.detach().sum()\n",
    "    importance = outs.detach().cpu().sum(dim=(0,1))\n",
    "    print(f\"{module.__class__.__name__} importance.shape: {importance.shape}\")\n",
    "\n",
    "    module.calculated_importance = importance\n",
    "\n",
    "def embedding_importance_hook(module, ins, outs) -> None:\n",
    "    # the first block's first processing layer will be the \n",
    "    # layer norm,\n",
    "    # so we'll just sum up the layer norm outputs after getting them\n",
    "   # calculate the importances\n",
    "    importance = outs.detach().sum(dim=(0,1))\n",
    "    # print(\"importance.shape:\", importance.shape)\n",
    "    # print(\"n_embd: \", outs.size(-1))\n",
    "    # print(\"module:\", module.__class__.__name__)\n",
    "    # print(\"outs.shape:\", outs.shape) # probably (B, T, E)\n",
    " \n",
    "    module.calculated_importance = importance\n",
    "\n",
    "    print(f\"{module.__class__.__name__} importance.shape: {importance.shape}\")\n",
    "\n",
    "def block_importance_hook(module, ins, outs) -> None:\n",
    "    \n",
    "    in_vectors = ins[0].detach()  # (B, T, E)\n",
    "    out_vectors = outs.detach()   # (B, T, E)\n",
    "    \n",
    "    # Calculate cosine similarity for each sample and time step\n",
    "    dot_product = torch.sum(in_vectors * out_vectors, dim=-1)  # (B, T)\n",
    "    in_norm = torch.norm(in_vectors, p=2, dim=-1)  # (B, T)\n",
    "    out_norm = torch.norm(out_vectors, p=2, dim=-1)  # (B, T)\n",
    "    \n",
    "    cosine_sim = dot_product / (in_norm * out_norm + 1e-8)  # (B, T)\n",
    "    \n",
    "    # Calculate BI by taking the expectation (mean) and subtracting from 1\n",
    "    block_importance = 1 - torch.mean(cosine_sim)\n",
    "    \n",
    "    # print(\"Block Importance:\", block_importance.item())\n",
    "    # print(\"module:\", module.__class__.__name__)\n",
    "    # print(\"outs.shape:\", outs.shape)  # (B, T, E)\n",
    " \n",
    "    module.calculated_importance = block_importance\n",
    "\n",
    "    print(f\"{module.__class__.__name__} importance.shape: {block_importance.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the initial hooks for all the corresponding layers\n",
    "from models import Block, GPT\n",
    "\n",
    "def delete_importance_attr(layer: nn.Module):\n",
    "    if hasattr(layer, \"calculated_importance\"):\n",
    "        del layer.calculated_importance\n",
    "\n",
    "def remove_all_forward_hooks(model: GPT):\n",
    "    if not isinstance(model, GPT):\n",
    "        raise NotImplementedError(\"Only GPT models are supported for now\")\n",
    "    \n",
    "    for module in model.modules():\n",
    "        if isinstance(module, Block):\n",
    "            for head in module.sa.heads:\n",
    "                head._forward_hooks.clear()\n",
    "                delete_importance_attr(head)\n",
    "\n",
    "            module.ffwd._forward_hooks.clear()\n",
    "            module.ln1._forward_hooks.clear()\n",
    "            module.sa._forward_hooks.clear()\n",
    "\n",
    "            delete_importance_attr(module.ffwd)\n",
    "            delete_importance_attr(module.ln1)\n",
    "            delete_importance_attr(module.sa)\n",
    "\n",
    "def register_all_forward_hooks(model: GPT):\n",
    "    if not isinstance(model, GPT):\n",
    "        raise NotImplementedError(\"Only GPT models are supported for now\")\n",
    "\n",
    "    num_blocks = 0\n",
    "    for module in loaded_model.modules():\n",
    "        if isinstance(module, Block):\n",
    "            num_blocks += 1\n",
    "            for head in module.sa.heads:\n",
    "                head.register_forward_hook(attn_head_importance_hook)\n",
    "            module.ffwd.register_forward_hook(neuron_importance_hook)\n",
    "            if num_blocks == 1:\n",
    "                module.ln1.register_forward_hook(embedding_importance_hook)\n",
    "            module.register_forward_hook(block_importance_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: PRUNING AND TRIMMING\n",
    "    # TODO: simple pruning strategy for pruning and trimming the models based on the given paper.\n",
    "    # TODO: implement a lightweight training pipeline using the calibration dataset and stabilize the rankings\n",
    "# TODO: implement knowledge distillation-based full retraining strategy based on the findings in the paper\n",
    "    # 5. Retrain exclusively with distillation loss using KLD instead of conventional training.\n",
    "    # 6. Use (logit+intermediate state+embedding) distillation when depth is reduced significantly.\n",
    "    # 7. Use logit-only distillation when depth isn’t reduced significantly.\n",
    "    # 8. Prune a model closest to the target size.\n",
    "    # 9. Perform lightweight retraining to stabilize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_forward_hooks(loaded_model)\n",
    "register_all_forward_hooks(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron and head pruning? \n",
    "\n",
    "# start with neuron pruning\n",
    "\n",
    "def prune_neurons(model, ratio=0.2) -> None:\n",
    "    # goal: trim the MLP layer weights\n",
    "    # 1 - argsort the importances of the `ffwd` layers defined in the model\n",
    "    # 2 - remove the weights with respect to the given ratio\n",
    "\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, Block):\n",
    "            importances = module.ffwd.calculated_importance\n",
    "            num_neurons = int(ratio * importances.size(0))\n",
    "            idx = importances.argsort(descending=True)[:num_neurons]\n",
    "            # reinitialize the weights along with the layer\n",
    "            dense1 = module.ffwd.net[0]\n",
    "            dense2 = module.ffwd.net[2]\n",
    "\n",
    "            dense1.weight.data = dense1.weight.data[idx, :]\n",
    "            dense1.bias.data = dense1.bias.data[idx]\n",
    "\n",
    "            dense2.weight.data = dense2.weight.data[idx, :]\n",
    "            dense2.bias.data = dense2.bias.data[idx]\n",
    "\n",
    "\n",
    "def prune_heads(model, ratio=0.2) -> None:\n",
    "    # goal: trim the attention heads' layer weights using the same approach as the `prune_neurons`\n",
    "    pass\n",
    "\n",
    "\n",
    "def prune_embeddings(model, ratio=0.2) -> None:\n",
    "    # goal: trim the embedding dimension of the weight matrices in MLP, MHA, and LayerNorm layers.\n",
    "    # TODO: check how embedding importance is calculated!\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinit_models():\n",
    "    loaded_model, tokenizer = load(GPT, \"model\")\n",
    "    loaded_model.to(device);\n",
    "\n",
    "    remove_all_forward_hooks(loaded_model)\n",
    "    register_all_forward_hooks(loaded_model)\n",
    "\n",
    "    return loaded_model, tokenizer\n",
    "\n",
    "model, tokenizer = reinit_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_neurons(loaded_model, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayerNorm importance.shape: torch.Size([256])\n",
      "LayerNorm importance.shape: torch.Size([256])\n",
      "LayerNorm importance.shape: torch.Size([256])\n",
      "LayerNorm importance.shape: torch.Size([256])\n",
      "LayerNorm importance.shape: torch.Size([256])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n",
      "Head importance: torch.Size([])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (8x256 and 51x51)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mloaded_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/models.py:174\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    170\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(\n\u001b[1;32m    171\u001b[0m     torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    172\u001b[0m )  \u001b[38;5;66;03m# (T, n_embd)\u001b[39;00m\n\u001b[1;32m    173\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb  \u001b[38;5;66;03m# (B, T, n_embd)\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, T, n_embd)\u001b[39;00m\n\u001b[1;32m    175\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(x)  \u001b[38;5;66;03m# (B, T, n_embd)\u001b[39;00m\n\u001b[1;32m    176\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_head(x)  \u001b[38;5;66;03m# (B, T, vocab_size)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1603\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1600\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1601\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1603\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1607\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1608\u001b[0m     ):\n\u001b[1;32m   1609\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/models.py:142\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    141\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(x))\n\u001b[0;32m--> 142\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1603\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1600\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1601\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1603\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1607\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1608\u001b[0m     ):\n\u001b[1;32m   1609\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/models.py:128\u001b[0m, in \u001b[0;36mFeedForward.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/coding/paper-implts/Compact_Language_Models_240714679/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: linear(): input and weight.T shapes cannot be multiplied (8x256 and 51x51)"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 8, dtype=torch.long, device=device)\n",
    "\n",
    "loaded_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (token_embedding_table): Embedding(65, 256)\n",
       "  (position_embedding_table): Embedding(128, 256)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (sa): MultiHeadAttentionConcat(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (sa): MultiHeadAttentionConcat(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (sa): MultiHeadAttentionConcat(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (sa): MultiHeadAttentionConcat(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (ln_head): Linear(in_features=256, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
